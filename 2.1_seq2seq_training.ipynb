{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3.5\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, model_from_json, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(''data/train/train_full.csv, encoding='utf-8').read().split('\\n')\n",
    "lines = lines[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = total_train[total_train.apply(lambda x: not x['classtag'].endswith(('-','+','0')), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sentences = []\n",
    "fra_sentences = []\n",
    "eng_chars = set()\n",
    "fra_chars = set()\n",
    "nb_samples = len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560640"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 422304/422304 [00:03<00:00, 127387.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process english and french sentences\n",
    "for line in tqdm(range(nb_samples)):\n",
    "    try:\n",
    "        lemma,gender,formtag,classtag,form = lines[line].split('\\t')\n",
    "        eng_line = lemma+formtag\n",
    "        #print(eng_line)\n",
    "        # Append '\\t' for start of the sentence and '\\n' to signify end of the sentence\n",
    "        fra_line = '\\t' + form + '\\n'\n",
    "        #print(fra_line)\n",
    "        eng_sentences.append(eng_line)\n",
    "        fra_sentences.append(fra_line)\n",
    "\n",
    "        for ch in eng_line:\n",
    "            if (ch not in eng_chars):\n",
    "                eng_chars.add(ch)\n",
    "\n",
    "        for ch in fra_line:\n",
    "            if (ch not in fra_chars):\n",
    "                fra_chars.add(ch)\n",
    "    except Exception as e:\n",
    "        print(line, lines[line], e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_chars = sorted(list(fra_chars))\n",
    "eng_chars = sorted(list(eng_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- 1 2 A D G I L N а б в г д е ж з и й к л м н о п р с т у ф х ц ч ш щ ъ ы ь э ю я ё'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(eng_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each english character - key is index and value is english character\n",
    "eng_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get english character given its index - key is english character and value is index\n",
    "eng_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(eng_chars):\n",
    "    eng_index_to_char_dict[k] = v\n",
    "    eng_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each french character - key is index and value is french character\n",
    "fra_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get french character given its index - key is french character and value is index\n",
    "fra_char_to_index_dict = {}\n",
    "for k, v in enumerate(fra_chars):\n",
    "    fra_index_to_char_dict[k] = v\n",
    "    fra_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_eng_sent = max([len(line) for line in eng_sentences])\n",
    "max_len_fra_sent = max([len(line) for line in fra_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['eng_chars'] = eng_chars\n",
    "data['fra_chars'] = fra_chars\n",
    "data['max_len_eng_sent'] = max_len_eng_sent\n",
    "data['max_len_fra_sent'] = max_len_fra_sent\n",
    "data['eng_index_to_char_dict'] = eng_index_to_char_dict\n",
    "data['eng_char_to_index_dict'] = eng_char_to_index_dict\n",
    "data['fra_index_to_char_dict'] = fra_index_to_char_dict\n",
    "data['fra_char_to_index_dict'] = fra_char_to_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling data for inference model\n",
    "pickle.dump(data, open( \"data.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"data.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "eng_chars = data['eng_chars']\n",
    "fra_chars = data['fra_chars']\n",
    "max_len_eng_sent = data['max_len_eng_sent']\n",
    "max_len_fra_sent = data['max_len_fra_sent']\n",
    "eng_index_to_char_dict = data['eng_index_to_char_dict']\n",
    "eng_char_to_index_dict = data['eng_char_to_index_dict']\n",
    "fra_index_to_char_dict = data['fra_index_to_char_dict']\n",
    "fra_char_to_index_dict = data['fra_char_to_index_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eng_sentences = np.zeros(shape = (nb_samples,max_len_eng_sent,len(eng_chars)), dtype='float32')\n",
    "tokenized_fra_sentences = np.zeros(shape = (nb_samples,max_len_fra_sent,len(fra_chars)), dtype='float32')\n",
    "target_data = np.zeros((nb_samples, max_len_fra_sent, len(fra_chars)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560640, 26, 42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_eng_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560640, 28, 37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_fra_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/560640 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3c18d237e4fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meng_sentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtokenized_eng_sentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meng_char_to_index_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Vectorize the english and french sentences\n",
    "\n",
    "for i in tqdm(range(nb_samples)):\n",
    "    for k,ch in enumerate(eng_sentences[i]):\n",
    "        tokenized_eng_sentences[i,k,eng_char_to_index_dict[ch]] = 1\n",
    "\n",
    "    for k,ch in enumerate(fra_sentences[i]):\n",
    "        tokenized_fra_sentences[i,k,fra_char_to_index_dict[ch]] = 1\n",
    "\n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i,k-1,fra_char_to_index_dict[ch]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "\n",
    "encoder_input = Input(shape=(None,len(eng_chars)))\n",
    "encoder_LSTM = LSTM(256,return_state = True)\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
    "encoder_states = [encoder_h, encoder_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(42)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "\n",
    "decoder_input = Input(shape=(None,len(fra_chars)))\n",
    "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(fra_chars),activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "#plot_model(tmodel, to_file='tmodel.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(x=[tokenized_eng_sentences,tokenized_fra_sentences], \n",
    "          y=target_data,\n",
    "          batch_size=64,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          #callbacks=callbacks_list,\n",
    "         verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating and saving inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_inf.save('seq2seq/encoder_total.h5')\n",
    "decoder_model_inf.save('seq2seq/decoder_total.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_inf.save('seq2seq/encoder_total.h5')\n",
    "decoder_model_inf.save('seq2seq/decoder_total.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3.5\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_model_inf = load_model('retraining_models/encoder-1.h5')\n",
    "decoder_model_inf = load_model('retraining_models/decoder-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3.5\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_model_inf = load_model('models/encoder_full_letters.h5')\n",
    "decoder_model_inf = load_model('models/decoder_full_letters.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del encoder_model_inf\n",
    "del decoder_model_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq,encoder_model_inf,decoder_model_inf):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(fra_chars)))\n",
    "    target_seq[0, 0, fra_char_to_index_dict['\\t']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    prob = 1.0\n",
    "    while not stop_condition:\n",
    "        \n",
    "        #decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        #predict_pr = decoder_model_inf.predict_proba(x=[target_seq] + states_val)\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        #print(decoder_out)\n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        max_val = np.max(decoder_out[0,-1,:])\n",
    "        prob *= max_val\n",
    "        sampled_fra_char = fra_index_to_char_dict[max_val_index]\n",
    "        translated_sent += sampled_fra_char\n",
    "        print('{} == {}'.format(sampled_fra_char,max_val))\n",
    "        \n",
    "        if ( (sampled_fra_char == '\\n') or (len(translated_sent) > max_len_fra_sent)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(fra_chars)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "    \n",
    "    prob = prob**(1/len(translated_sent))\n",
    "    return translated_sent, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(seq):\n",
    "    tokenized_eng_sentence = np.zeros(shape = (1,max_len_eng_sent,len(eng_chars)), dtype='float32')\n",
    "    for k,ch in enumerate(seq):\n",
    "        tokenized_eng_sentence[0,k,eng_char_to_index_dict[ch]] = 1\n",
    "        \n",
    "    return tokenized_eng_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "б == 0.9932345747947693\n",
      "р == 1.0\n",
      "а == 1.0\n",
      "т == 1.0\n",
      "ь == 0.9999997615814209\n",
      "е == 0.9999508857727051\n",
      "в == 1.0\n",
      "\n",
      " == 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991456441333508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = 'брат2G'\n",
    "inp_seq = tokenize(inp)\n",
    "translated_sent,prob = decode_seq(inp_seq,encoder_model_inf,decoder_model_inf)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-d498dbd4683d>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-d498dbd4683d>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    tags = [[i,k,n + c] for i,n in enumerate(['1','2']) for k,c in enumerate(['N','G','D','A','I','L'])]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "word = 'огуречик'\n",
    "d = pd.DataFrame(np.zeros((6, 2)),index=['Nom','Gen','Dat','Acc','Ins','Loc',],columns=['Singular','Plural'])\n",
    "    tags = [[i,k,n + c] for i,n in enumerate(['1','2']) for k,c in enumerate(['N','G','D','A','I','L'])]\n",
    "    for n,c,tag in tags:\n",
    "        inp = word + tag\n",
    "        inp_seq = tokenize(inp)\n",
    "        translated_sent = decode_seq(inp_seq)\n",
    "        d.iloc[c,n] = translated_sent.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob**(1/len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
