{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as npd\n",
    "import pandas as pd\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('data/data_lower.csv', sep='\\t', encoding = 'utf-8')\n",
    "DF = DF[DF.apply(lambda x: not x['classtag'].endswith(('-','+','0')), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего классов 259\n",
      "  classtag  total_count\n",
      "0      м1а         7647\n",
      "1      ж8а         3747\n",
      "2      с7а         3625\n",
      "3     ж3*а         3606\n",
      "4     мо1а         2891\n"
     ]
    }
   ],
   "source": [
    "#создадим список классов по частотности\n",
    "df_classes = DF[['classtag']].copy()\n",
    "df_classes['total_count'] = [1] * df_classes.shape[0]\n",
    "df_classes = df_classes.groupby(['classtag'], sort=True).aggregate(sum) #создаем таблицу класс * количество парадигм\n",
    "df_classes = df_classes.sort_values(by=['total_count'], ascending=False) #сортируем от большего к меньшему\n",
    "df_classes = df_classes.reset_index(level=['classtag'])\n",
    "cl_list = list(df_classes['classtag']) # сам список классов по убыванию\n",
    "print('всего классов',df_classes.shape[0])\n",
    "print(df_classes[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "классов, в которых не больше 4 слов: 153\n",
      "парадигм в этих классах: 265\n"
     ]
    }
   ],
   "source": [
    "tail_df = df_classes.loc[df_classes['total_count'] <= 4] # \"хвост\" из маленьких классов, который просто выучим\n",
    "print('классов, в которых не больше 4 слов:', tail_df.loc[tail_df['total_count'] <= 4].shape[0])\n",
    "print('парадигм в этих классах:', tail_df['total_count'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short format to long format\n",
    "def short_to_long(df):\n",
    "    print('\\n')\n",
    "    print('short format dataframe with {} lemmas'.format(df.shape[0]))\n",
    "    #print(df.iloc[0:5,0:5])\n",
    "    df_long = pd.wide_to_long(df, stubnames = 'form', i = ['lemma','gender'], j = 'formtag')\n",
    "    df_long = df_long.sample(frac=1, random_state=15) #перемешиваем строки\n",
    "    print('made long format dataframe with {} wordforms'.format(df_long.shape[0]))\n",
    "    #print(df_long[:5])\n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split \n",
    "def train_and_test(classes):\n",
    "    dataset = list(zip([], [], [], [], [], [], [], [], [], [], [], [], [], [], []))\n",
    "    train = pd.DataFrame(data=dataset, columns=['lemma', 'gender', 'classtag',  \n",
    "                                                \"form1N\",\"form1G\",\"form1D\",\"form1A\",\"form1I\",\"form1L\",\n",
    "                                                \"form2N\",\"form2G\",\"form2D\",\"form2A\",\"form2I\",\"form2L\"])\n",
    "    test = train.copy()\n",
    "    for classtag in classes:\n",
    "        #print('класс:', classtag)\n",
    "        paradigms = DF.loc[DF['classtag'] == classtag]\n",
    "        paradigms = paradigms.sample(frac=1, random_state=12345) #перемешиваем строки\n",
    "        n = paradigms.shape[0]\n",
    "        #print('всего парадигм:', n)\n",
    "        n_train = ceil(n*0.75)\n",
    "        train_df,test_df = paradigms[:n_train], paradigms[n_train:]\n",
    "        #print('train: + {} парадигм'.format(train_df.shape[0]))\n",
    "        train = train.append(train_df)\n",
    "        #print('test: + {} парадигм\\n'.format(test_df.shape[0]))\n",
    "        test = test.append(test_df)\n",
    "    train = short_to_long(train)\n",
    "    test = short_to_long(test)\n",
    "    return train,test\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### создаем 2 файла для первого эксперимента: train_full.csv (3/4 от всех классов), test_full.csv для обучения самой полной модели, которую сравним с pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "short format dataframe with 31961 lemmas\n",
      "made long format dataframe with 383532 wordforms\n",
      "\n",
      "\n",
      "short format dataframe with 10533 lemmas\n",
      "made long format dataframe with 126396 wordforms\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#для каждого класса делим парадигмы на 0.75 трейн и 0.25 тест (классы из хвоста все уходят в трейн)\n",
    "train, test = train_and_test(cl_list)\n",
    "test.to_csv('data/test/test_full.csv', sep='\\t', encoding = 'utf-8')\n",
    "train.to_csv('data/train/train_full.csv', sep='\\t', encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
