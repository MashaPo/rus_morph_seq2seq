{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3.5\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, model_from_json, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "#from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using pretrained model from module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import predict_form,predict_paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = load_model('decoder_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'огуречикам'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_form('огуречик23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singular</th>\n",
       "      <th>Plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nom</th>\n",
       "      <td>нивнетарь</td>\n",
       "      <td>инвентари</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gen</th>\n",
       "      <td>инвентаря</td>\n",
       "      <td>инвентарей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dat</th>\n",
       "      <td>инвентарю</td>\n",
       "      <td>инвентарям</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc</th>\n",
       "      <td>инвентарь</td>\n",
       "      <td>инвентари</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ins</th>\n",
       "      <td>инвентарём</td>\n",
       "      <td>инвентарями</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc</th>\n",
       "      <td>инвентаре</td>\n",
       "      <td>инвентарях</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Singular       Plural\n",
       "Nom   нивнетарь    инвентари\n",
       "Gen   инвентаря   инвентарей\n",
       "Dat   инвентарю   инвентарям\n",
       "Acc   инвентарь    инвентари\n",
       "Ins  инвентарём  инвентарями\n",
       "Loc   инвентаре   инвентарях"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_paradigm('инвентарь')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or step-by-step usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines = open('C:/hse_compling/gits/ML-AI-experiments/AI/Neural Machine Translation/fra.txt', encoding='utf-8').read().split('\\n')\n",
    "lines = open('C:/hse_compling/diploma/data/data_lower_long.csv', encoding='utf-8').read().split('\\n')\n",
    "lines = lines[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sentences = []\n",
    "fra_sentences = []\n",
    "eng_chars = set()\n",
    "fra_chars = set()\n",
    "nb_samples = len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560640"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 560640/560640 [00:04<00:00, 130387.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process english and french sentences\n",
    "for line in tqdm(range(nb_samples)):\n",
    "    try:\n",
    "        lemma,gender,formtag,classtag,form = lines[line].split('\\t')\n",
    "        eng_line = lemma+formtag\n",
    "        #print(eng_line)\n",
    "        # Append '\\t' for start of the sentence and '\\n' to signify end of the sentence\n",
    "        fra_line = '\\t' + form + '\\n'\n",
    "        #print(fra_line)\n",
    "        eng_sentences.append(eng_line)\n",
    "        fra_sentences.append(fra_line)\n",
    "\n",
    "        for ch in eng_line:\n",
    "            if (ch not in eng_chars):\n",
    "                eng_chars.add(ch)\n",
    "\n",
    "        for ch in fra_line:\n",
    "            if (ch not in fra_chars):\n",
    "                fra_chars.add(ch)\n",
    "    except Exception as e:\n",
    "        print(line, lines[line], e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_chars = sorted(list(fra_chars))\n",
    "eng_chars = sorted(list(eng_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each english character - key is index and value is english character\n",
    "eng_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get english character given its index - key is english character and value is index\n",
    "eng_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(eng_chars):\n",
    "    eng_index_to_char_dict[k] = v\n",
    "    eng_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to index each french character - key is index and value is french character\n",
    "fra_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get french character given its index - key is french character and value is index\n",
    "fra_char_to_index_dict = {}\n",
    "for k, v in enumerate(fra_chars):\n",
    "    fra_index_to_char_dict[k] = v\n",
    "    fra_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_eng_sent = max([len(line) for line in eng_sentences])\n",
    "max_len_fra_sent = max([len(line) for line in fra_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_eng_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_fra_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eng_sentences = np.zeros(shape = (nb_samples,max_len_eng_sent,len(eng_chars)), dtype='float32')\n",
    "tokenized_fra_sentences = np.zeros(shape = (nb_samples,max_len_fra_sent,len(fra_chars)), dtype='float32')\n",
    "target_data = np.zeros((nb_samples, max_len_fra_sent, len(fra_chars)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560892, 28, 37)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_fra_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3.5\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_model_inf = load_model('encoder.h5')\n",
    "decoder_model_inf = load_model('decoder.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(fra_chars)))\n",
    "    target_seq[0, 0, fra_char_to_index_dict['\\t']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    prob = 1.0\n",
    "    while not stop_condition:\n",
    "        \n",
    "        #decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        #predict_pr = decoder_model_inf.predict_proba(x=[target_seq] + states_val)\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        #print(decoder_out)\n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        max_val = np.max(decoder_out[0,-1,:])\n",
    "        prob *= max_val\n",
    "        sampled_fra_char = fra_index_to_char_dict[max_val_index]\n",
    "        translated_sent += sampled_fra_char\n",
    "        \n",
    "        if ( (sampled_fra_char == '\\n') or (len(translated_sent) > max_len_fra_sent)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(fra_chars)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "    \n",
    "    prob /= len(translated_sent)\n",
    "    return translated_sent, prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(seq):\n",
    "    tokenized_eng_sentence = np.zeros(shape = (1,max_len_eng_sent,len(eng_chars)), dtype='float32')\n",
    "    for k,ch in enumerate(seq):\n",
    "        tokenized_eng_sentence[0,k,eng_char_to_index_dict[ch]] = 1\n",
    "        \n",
    "    return tokenized_eng_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "огуречика\n",
      " 0.09996409422165156\n"
     ]
    }
   ],
   "source": [
    "word = 'огуречик'\n",
    "d = pd.DataFrame(np.zeros((6, 2)),index=['Nom','Gen','Dat','Acc','Ins','Loc',],columns=['Singular','Plural'])\n",
    "tags = [[n,c,str(n)+str(c)] for n in [1,2] for c in [1,2,3,4,5,6]]\n",
    "tag = '12'\n",
    "inp = word + tag\n",
    "inp_seq = tokenize(inp)\n",
    "translated_sent, prob = decode_seq(inp_seq)\n",
    "print(translated_sent, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singular</th>\n",
       "      <th>Plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nom</th>\n",
       "      <td>огуречик</td>\n",
       "      <td>огуречики</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gen</th>\n",
       "      <td>огуречика</td>\n",
       "      <td>огуречиков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dat</th>\n",
       "      <td>огуречику</td>\n",
       "      <td>огуречикам</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc</th>\n",
       "      <td>огуречик</td>\n",
       "      <td>огуречиков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ins</th>\n",
       "      <td>огуречиком</td>\n",
       "      <td>огуречиками</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc</th>\n",
       "      <td>огуречике</td>\n",
       "      <td>огуречиках</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Singular       Plural\n",
       "Nom    огуречик    огуречики\n",
       "Gen   огуречика   огуречиков\n",
       "Dat   огуречику   огуречикам\n",
       "Acc    огуречик   огуречиков\n",
       "Ins  огуречиком  огуречиками\n",
       "Loc   огуречике   огуречиках"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'огуречик'\n",
    "d = pd.DataFrame(np.zeros((6, 2)),index=['Nom','Gen','Dat','Acc','Ins','Loc',],columns=['Singular','Plural'])\n",
    "tags = [[n,c,str(n)+str(c)] for n in [1,2] for c in [1,2,3,4,5,6]]\n",
    "for n,c,tag in tags:\n",
    "    inp = word + tag\n",
    "    inp_seq = tokenize(inp)\n",
    "    translated_sent = decode_seq(inp_seq)\n",
    "    d.iloc[c-1,n-1] = translated_sent.rstrip()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
